import os
import faiss
import numpy as np
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
import google.generativeai as genai
from dotenv import load_dotenv

# --- Load API Key ---
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# --- RAG Pipeline Class ---
class RAGPipeline:
    def __init__(self, index_dir="rag_indexes"):
        self.embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

        # Directories
        self.index_dir = index_dir
        self.temp_index_dir = os.path.join(index_dir, "temp")
        os.makedirs(self.index_dir, exist_ok=True)
        os.makedirs(self.temp_index_dir, exist_ok=True)

    # --- Embedding helper ---
    def encode_norm(self, texts):
        if not texts:
            return np.empty((0, self.embedder.get_sentence_embedding_dimension()), dtype="float32")
        return self.embedder.encode(texts, normalize_embeddings=True).astype("float32")

    # --- FAISS utilities ---
    def _new_ip_index(self, dim):
        return faiss.IndexFlatIP(dim)

    # --- PDF Loader ---
    def load_and_chunk_pdf(self, file_path, chunk_size=800, chunk_overlap=100):
        reader = PdfReader(file_path)
        text = ""
        for page in reader.pages:
            if page.extract_text():
                text += page.extract_text()

        if not text.strip():
            return []

        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        chunks = splitter.split_text(text)
        return [c.strip() for c in chunks if c and c.strip()]

    # --- Update session FAISS index ---
    def update_session_faiss(self, docs, session_id):
        if not docs:
            return False

        doc_embeddings = self.encode_norm(docs)
        if doc_embeddings.shape[0] == 0:
            return False

        dim = doc_embeddings.shape[1]

        # Session index
        session_index = self._new_ip_index(dim)
        session_index.add(doc_embeddings)

        session_index_path = os.path.join(self.temp_index_dir, f"{session_id}_index.faiss")
        session_docs_path = os.path.join(self.temp_index_dir, f"{session_id}_docs.npy")

        faiss.write_index(session_index, session_index_path)
        np.save(session_docs_path, docs)

        return True

    # --- Load session index ---
    def load_session_index(self, session_id):
        session_index_path = os.path.join(self.temp_index_dir, f"{session_id}_index.faiss")
        session_docs_path = os.path.join(self.temp_index_dir, f"{session_id}_docs.npy")
        if not os.path.exists(session_index_path) or not os.path.exists(session_docs_path):
            raise FileNotFoundError("Session index/docs not found.")
        index = faiss.read_index(session_index_path)
        docs = np.load(session_docs_path, allow_pickle=True)
        return index, docs

    # --- Retrieval ---
    def retrieve_with_scores(self, query, index, docs, k=3):
        q_emb = self.encode_norm([query])
        if q_emb.shape[0] == 0:
            return []

        scores, idxs = index.search(q_emb, k)
        results = []
        for score, idx in zip(scores[0], idxs[0]):
            if idx == -1: continue
            results.append((docs[idx], float(score)))
        results.sort(key=lambda x: x[1], reverse=True)
        return results

    # --- Query Gemini (session-only) ---
    def ask(self, query, session_id=None, k=3, sim_threshold=0.3):
        if not session_id:
            return "❌ Session ID is required for uploaded document queries."

        # Session search
        try:
            s_index, s_docs = self.load_session_index(session_id)
            session_results = self.retrieve_with_scores(query, s_index, s_docs, k)
        except FileNotFoundError:
            return "❌ No document uploaded for this session."

        session_results = [r for r in session_results if r[1] >= sim_threshold]

        if session_results:
            context = "\n\n---\n\n".join([doc for doc, _ in session_results])
            prompt = f"""
You are a helpful AI assistant.
Answer using the uploaded document context below.
Do not invent anything outside this context.

Uploaded Document Context:
{context}

Question: {query}
Answer clearly:
""".strip()
            model = genai.GenerativeModel("gemini-1.5-flash")
            response = model.generate_content(prompt)
            return response.text.strip()

        return "❌ This query isn’t in the uploaded document."


# --- Wrappers for Django views.py ---
rag = RAGPipeline()

def process_file_with_rag(file_path, session_id):
    docs = rag.load_and_chunk_pdf(file_path)
    rag.update_session_faiss(docs, session_id)
    return f"Added {len(docs)} chunks for session {session_id}"

def ask_gemini(query, session_id=None):
    return rag.ask(query, session_id)
